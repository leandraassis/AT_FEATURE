{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b361d3a",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b672bfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e92fe8",
   "metadata": {},
   "source": [
    "#### Remoção de StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d6c14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  sentiment\n",
      "0  bromwell high cartoon comedy ran time programs...          1\n",
      "1  homelessness houselessness george carlin state...          1\n",
      "2  brilliant overacting lesley ann warren best dr...          1\n",
      "3  easily underrated film inn brooks cannon sure ...          1\n",
      "4  typical mel brooks film much less slapstick mo...          1\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remover_stopwords(texto):\n",
    "    texto = texto.lower()\n",
    "    texto = texto.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(texto)\n",
    "    tokens_filtrados = [p for p in tokens if p not in stop_words]\n",
    "    return ' '.join(tokens_filtrados)\n",
    "\n",
    "def carregar_reviews_stopwords(caminho_base):\n",
    "    textos = []\n",
    "    sentimentos = []\n",
    "\n",
    "    for sentimento in ['pos', 'neg']:\n",
    "        pasta = os.path.join(caminho_base, sentimento)\n",
    "        for nome_arquivo in os.listdir(pasta):\n",
    "            caminho_arquivo = os.path.join(pasta, nome_arquivo)\n",
    "            with open(caminho_arquivo, encoding='utf-8') as f:\n",
    "                texto_original = f.read()\n",
    "                texto_processado = remover_stopwords(texto_original)\n",
    "                textos.append(texto_processado)\n",
    "                sentimentos.append(1 if sentimento == 'pos' else 0)\n",
    "\n",
    "    return pd.DataFrame({'review': textos, 'sentiment': sentimentos})\n",
    "\n",
    "caminho_train = 'resenhas_dataset/aclImdb/train'\n",
    "caminho_test = 'resenhas_dataset/aclImdb/test'\n",
    "\n",
    "df_train = carregar_reviews_stopwords(caminho_train)\n",
    "df_test = carregar_reviews_stopwords(caminho_test)\n",
    "\n",
    "df_stopwords_removidas = pd.concat([df_train, df_test], ignore_index=True)\n",
    "\n",
    "print(df_stopwords_removidas.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459105b0",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f91dd49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  sentiment\n",
      "0  bromwel high cartoon comedi ran time program s...          1\n",
      "1  homeless houseless georg carlin state issu yea...          1\n",
      "2  brilliant overact lesley ann warren best drama...          1\n",
      "3  easili underr film inn brook cannon sure flaw ...          1\n",
      "4  typic mel brook film much less slapstick movi ...          1\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def aplicar_stemming(texto):\n",
    "    tokens = word_tokenize(texto)\n",
    "    tokens_stem = [stemmer.stem(p) for p in tokens]\n",
    "    return ' '.join(tokens_stem)\n",
    "\n",
    "df_stemmer = df_stopwords_removidas.copy()\n",
    "df_stemmer['review'] = df_stemmer['review'].apply(aplicar_stemming)\n",
    "\n",
    "print(df_stemmer.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e051c19f",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b64295df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  sentiment\n",
      "0  bromwell high cartoon comedy ran time program ...          1\n",
      "1  homelessness houselessness george carlin state...          1\n",
      "2  brilliant overacting lesley ann warren best dr...          1\n",
      "3  easily underrated film inn brook cannon sure f...          1\n",
      "4  typical mel brook film much less slapstick mov...          1\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def aplicar_lemmatizer(texto):\n",
    "    tokens = word_tokenize(texto)\n",
    "    tokens_lemma = [lemmatizer.lemmatize(p) for p in tokens]\n",
    "    return ' '.join(tokens_lemma)\n",
    "\n",
    "df_lemmatization = df_stopwords_removidas.copy()\n",
    "df_lemmatization['review'] = df_lemmatization['review'].apply(aplicar_lemmatizer)\n",
    "\n",
    "print(df_lemmatization.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d74053e",
   "metadata": {},
   "source": [
    "#### Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07f223df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado: (50000, 142188)\n"
     ]
    }
   ],
   "source": [
    "bow = CountVectorizer()\n",
    "\n",
    "resultado_bow = bow.fit_transform(df_stemmer['review'])\n",
    "\n",
    "print(\"Resultado:\", resultado_bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094e9236",
   "metadata": {},
   "source": [
    "#### Bag-of-Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41b4c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado: (50000, 3053156)\n",
      "Exemplo:  ['00 acting' '00 agent' '00 come' '00 including' '00 schneider' '00 worth'\n",
      " '000 000' '000 overboard' '000 produce' '0000000000001 10']\n"
     ]
    }
   ],
   "source": [
    "bigrams = CountVectorizer(ngram_range=(2, 2))\n",
    "\n",
    "resultado_bigrams = bigrams.fit_transform(df_lemmatization['review'])\n",
    "\n",
    "print(\"Resultado:\", resultado_bigrams.shape)\n",
    "print(bigrams.get_feature_names_out()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64442f9",
   "metadata": {},
   "source": [
    "#### QUESTÃO 6 - TF-IDF e Regressão Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7799176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.8998\n"
     ]
    }
   ],
   "source": [
    "X = df_stopwords_removidas['review']\n",
    "y = df_stopwords_removidas['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Acurácia:\", accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AT_FEATURE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
